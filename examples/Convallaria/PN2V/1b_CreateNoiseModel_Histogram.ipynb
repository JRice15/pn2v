{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a Histogram Based Noise Model\n",
    "We will use pairs of noisy observations $x_i$ and clean signal $s_i$ (created by averaging many noisy images) to estimate the conditional distribution $p(x_i|s_i)$.\n",
    "Note that this noise model is independent of the image content. It is a property of the camera and imaging conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\") \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import pn2v.utils\n",
    "import pn2v.histNoiseModel\n",
    "from pn2v import prediction\n",
    "from tifffile import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "Download the data from  https://owncloud.mpi-cbg.de/index.php/s/224xGSeHquMbQYu. The link contains three different datasets (Convallaria, mouse skull nuclei and mouse actin). Here we show the pipeline for Convallaria dataset. Load the appropriate dataset from the right path. For us, the path is data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data\n",
    "\n",
    "The noise model is a characteristic of your camera. \n",
    "The downloaded data folder contains a set of calibration images (For the Convallaria dataset, it is 20190726_tl_50um_500msec_wf_130EM_FD.tif and the data to be denoised is named 20190520_tl_25um_50msec_05pc_488_130EM_Conv.tif)\n",
    "We can either create a histogram with noisy-GT pairs from data and calibration images or we can bootstrap a suitable histogram noise model after denoising the noisy images with Noise2Void and then using these denoised images as pseudo GT.\n",
    "\n",
    "Below we will define some parameters to identify the mode calibration data/bootstrap as well as noise model names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../../data/Convallaria_diaphragm/\"\n",
    "dataName = 'convallaria' # Name of the noise model \n",
    "mode='calibration' # Either `bootstrap` or `calibration`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode =='bootstrap': # Bootstrapping mode \n",
    "    nameN2VModel = dataName+'_n2v'\n",
    "    observation= imread(path+'20190520_tl_25um_50msec_05pc_488_130EM_Conv.tif') #Load the appropriate data\n",
    "    net=torch.load(path+\"/last_\"+nameN2VModel+\".net\")\n",
    "else: \n",
    "    nameN2VModel= None\n",
    "    observation= imread(path+'20190726_tl_50um_500msec_wf_130EM_FD.tif') # Load the appropriate data\n",
    "\n",
    "nameNoiseModel = path+'noiseModelHistogram_'+ dataName+'_'+mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode=='bootstrap':\n",
    "    # This cell is only run if bootstrap mode is selected. This performs N2V denoising for generating pseudoGT.\n",
    "    results=[]\n",
    "    meanRes=[]\n",
    "    resultImgs=[]\n",
    "    inputImgs=[]\n",
    "    dataTest = observation\n",
    "\n",
    "    for index in range(dataTest.shape[0]):\n",
    "\n",
    "        im=dataTest[index]\n",
    "        # We are using tiling to fit the image into memory\n",
    "        # If you get an error try a smaller patch size (ps)\n",
    "        means = prediction.tiledPredict(im, net, ps=256, overlap=48,\n",
    "                                                device=device, noiseModel=None)\n",
    "        resultImgs.append(means)\n",
    "        inputImgs.append(im)\n",
    "        print (\"image:\", index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first take a look at the distribution of signals $s_i$ that are present in this data.\n",
    "While most pixels are background, we comfortably cover a range to values of 30000 and below. The signals in the images we want to denoise should be within this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkSignalHist = np.histogram(signal, bins=256)\n",
    "plt.plot( checkSignalHist[1][:-1], np.clip(checkSignalHist[0],0,20000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the noise model\n",
    "Using the raw pixels $x_i$, and our pseudo ground truth $s_i$, we are now creating a 2D histogram. Rows correspond to different signals $s_i$ and columns to different observations $x_i$. The histogram is normalized so that every row sums to one. It describes the distribution $p(x_i|s_i)$ for each $s_i$. This distribution is our noise model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data contains 100 images of a static sample.\n",
    "# In case using calibration data mode, we estimate the clean signal by averaging all images.\n",
    "# In bootstrap mode, we estimate pseudo GT by using N2V denoised images.\n",
    "if mode=='bootstrap':\n",
    "    signal = np.array(resultImgs)   \n",
    "else:\n",
    "    signal=np.mean(observation,axis=0)[np.newaxis,...]\n",
    "\n",
    "# Let's look the raw data and our pseudo ground truth signal\n",
    "print(signal.shape)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(label='average (ground truth)')\n",
    "plt.imshow(signal[0],cmap='gray')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(label='single raw image')\n",
    "plt.imshow(observation[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the range of values we want to cover with our model.\n",
    "# The pixel intensities in the images you want to denoise have to lie within this range.\n",
    "# The dataset is clipped to values between 0 and 255.\n",
    "minVal, maxVal = 234, 7402\n",
    "bins = 256\n",
    "\n",
    "# We are creating the histogram.\n",
    "# This can take a minute.\n",
    "histogram = pn2v.histNoiseModel.createHistogram(bins,minVal,maxVal,observation,signal)\n",
    "\n",
    "# Saving histogram to disc.\n",
    "np.save(path+nameNoiseModel+'.npy', histogram)\n",
    "histogramFD=histogram[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize noise model for a specific signal-bin \n",
    "\n",
    "Below we just visualize our GMM based noise model for any given signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the noise model\n",
    "plt.xlabel('observation bin')\n",
    "plt.ylabel('signal bin')\n",
    "plt.imshow(histogramFD**0.25, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals=np.arange(bins)/float(bins)*(maxVal-minVal)+minVal\n",
    "plt.xlabel('observation')\n",
    "plt.ylabel('probability density')\n",
    "\n",
    "# We will now look at the noise distributions for different signals s_i,\n",
    "# by plotting individual rows of the histogram\n",
    "index=10\n",
    "s=((index+0.5)/float(bins)*(maxVal-minVal)+minVal)\n",
    "plt.plot(xvals,histogramFD[index,:], label='bin='+str(index)+' signal='+str(np.round(s,2)))\n",
    "\n",
    "index=50\n",
    "s=((index+0.5)/float(bins)*(maxVal-minVal)+minVal)\n",
    "plt.plot(xvals,histogramFD[index,:], label='bin='+str(index)+' signal='+str(np.round(s,2)))\n",
    "\n",
    "index=100\n",
    "s=((index+0.5)/float(bins)*(maxVal-minVal)+minVal)\n",
    "plt.plot(xvals,histogramFD[index,:], label='bin='+str(index)+' signal='+str(np.round(s,2)))\n",
    "\n",
    "index=200\n",
    "s=((index+0.5)/float(bins)*(maxVal-minVal)+minVal)\n",
    "plt.plot(xvals,histogramFD[index,:], label='bin='+str(index)+' signal='+str(np.round(s,2)))\n",
    "\n",
    "index=225\n",
    "s=((index+0.5)/float(bins)*(maxVal-minVal)+minVal)\n",
    "plt.plot(xvals,histogramFD[index,:], label='bin='+str(index)+' signal='+str(np.round(s,2)))\n",
    "\n",
    "index=250\n",
    "s=((index+0.5)/float(bins)*(maxVal-minVal)+minVal)\n",
    "plt.plot(xvals,histogramFD[index,:], label='bin='+str(index)+' signal='+str(np.round(s,2)))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppn2vEnv",
   "language": "python",
   "name": "ppn2env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
